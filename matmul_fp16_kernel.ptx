//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-30672275
// Cuda compilation tools, release 11.5, V11.5.119
// Based on NVVM 7.0.1
//

.version 7.5
.target sm_86
.address_size 64

	// .globl	matmul_transb_fp16
// _ZZ18matmul_transb_fp16E8shared_A has been demoted
// _ZZ18matmul_transb_fp16E8shared_B has been demoted

.visible .entry matmul_transb_fp16(
	.param .u64 matmul_transb_fp16_param_0,
	.param .u64 matmul_transb_fp16_param_1,
	.param .u64 matmul_transb_fp16_param_2,
	.param .align 2 .b8 matmul_transb_fp16_param_3[2],
	.param .align 2 .b8 matmul_transb_fp16_param_4[2],
	.param .u32 matmul_transb_fp16_param_5,
	.param .u32 matmul_transb_fp16_param_6,
	.param .u32 matmul_transb_fp16_param_7
)
{
	.reg .pred 	%p<12>;
	.reg .b16 	%rs<55>;
	.reg .f32 	%f<58>;
	.reg .b32 	%r<36>;
	.reg .b64 	%rd<16>;
	// demoted variable
	.shared .align 2 .b8 _ZZ18matmul_transb_fp16E8shared_A[544];
	// demoted variable
	.shared .align 2 .b8 _ZZ18matmul_transb_fp16E8shared_B[544];

	ld.param.u16 	%rs8, [matmul_transb_fp16_param_4];
	ld.param.u16 	%rs7, [matmul_transb_fp16_param_3];
	ld.param.u64 	%rd5, [matmul_transb_fp16_param_0];
	ld.param.u64 	%rd6, [matmul_transb_fp16_param_1];
	ld.param.u64 	%rd7, [matmul_transb_fp16_param_2];
	ld.param.u32 	%r18, [matmul_transb_fp16_param_5];
	ld.param.u32 	%r19, [matmul_transb_fp16_param_6];
	ld.param.u32 	%r20, [matmul_transb_fp16_param_7];
	mov.u32 	%r21, %ctaid.x;
	shl.b32 	%r22, %r21, 4;
	mov.u32 	%r1, %tid.x;
	add.s32 	%r2, %r22, %r1;
	mov.u32 	%r23, %ctaid.y;
	shl.b32 	%r3, %r23, 4;
	mov.u32 	%r33, %tid.y;
	add.s32 	%r5, %r3, %r33;
	setp.lt.s32 	%p1, %r20, 1;
	mov.f32 	%f57, 0f00000000;
	@%p1 bra 	$L__BB0_9;

	mul.lo.s32 	%r25, %r1, 34;
	mov.u32 	%r26, _ZZ18matmul_transb_fp16E8shared_A;
	add.s32 	%r8, %r26, %r25;
	shl.b32 	%r27, %r33, 1;
	add.s32 	%r6, %r8, %r27;
	mov.u32 	%r28, _ZZ18matmul_transb_fp16E8shared_B;
	add.s32 	%r29, %r28, %r25;
	add.s32 	%r7, %r29, %r27;
	mad.lo.s32 	%r9, %r33, 34, %r28;
	add.s32 	%r30, %r19, 1;
	mad.lo.s32 	%r34, %r33, %r30, %r3;
	shl.b32 	%r11, %r19, 4;
	mad.lo.s32 	%r31, %r20, %r2, %r33;
	cvta.to.global.u64 	%rd8, %rd5;
	mul.wide.s32 	%rd9, %r31, 2;
	add.s64 	%rd15, %rd8, %rd9;
	cvta.to.global.u64 	%rd2, %rd6;
	mov.u32 	%r35, 0;
	setp.lt.s32 	%p3, %r2, %r18;
	setp.lt.s32 	%p5, %r5, %r19;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs10, %f57;}

	// end inline asm

$L__BB0_2:
	setp.lt.s32 	%p2, %r33, %r20;
	and.pred  	%p4, %p3, %p2;
	@%p4 bra 	$L__BB0_4;
	bra.uni 	$L__BB0_3;

$L__BB0_4:
	ld.global.u16 	%rs53, [%rd15];
	bra.uni 	$L__BB0_5;

$L__BB0_3:
	mov.u16 	%rs53, %rs10;

$L__BB0_5:
	st.shared.u16 	[%r6], %rs53;
	and.pred  	%p7, %p5, %p2;
	@%p7 bra 	$L__BB0_7;
	bra.uni 	$L__BB0_6;

$L__BB0_7:
	mul.wide.s32 	%rd10, %r34, 2;
	add.s64 	%rd11, %rd2, %rd10;
	ld.global.u16 	%rs54, [%rd11];
	bra.uni 	$L__BB0_8;

$L__BB0_6:
	mov.u16 	%rs54, %rs10;

$L__BB0_8:
	st.shared.u16 	[%r7], %rs54;
	bar.sync 	0;
	ld.shared.u16 	%rs11, [%r8];
	// begin inline asm
	{  cvt.f32.f16 %f8, %rs11;}

	// end inline asm
	ld.shared.u16 	%rs12, [%r9];
	// begin inline asm
	{  cvt.f32.f16 %f9, %rs12;}

	// end inline asm
	fma.rn.f32 	%f40, %f8, %f9, %f57;
	ld.shared.u16 	%rs13, [%r8+2];
	// begin inline asm
	{  cvt.f32.f16 %f10, %rs13;}

	// end inline asm
	ld.shared.u16 	%rs14, [%r9+2];
	// begin inline asm
	{  cvt.f32.f16 %f11, %rs14;}

	// end inline asm
	fma.rn.f32 	%f41, %f10, %f11, %f40;
	ld.shared.u16 	%rs15, [%r8+4];
	// begin inline asm
	{  cvt.f32.f16 %f12, %rs15;}

	// end inline asm
	ld.shared.u16 	%rs16, [%r9+4];
	// begin inline asm
	{  cvt.f32.f16 %f13, %rs16;}

	// end inline asm
	fma.rn.f32 	%f42, %f12, %f13, %f41;
	ld.shared.u16 	%rs17, [%r8+6];
	// begin inline asm
	{  cvt.f32.f16 %f14, %rs17;}

	// end inline asm
	ld.shared.u16 	%rs18, [%r9+6];
	// begin inline asm
	{  cvt.f32.f16 %f15, %rs18;}

	// end inline asm
	fma.rn.f32 	%f43, %f14, %f15, %f42;
	ld.shared.u16 	%rs19, [%r8+8];
	// begin inline asm
	{  cvt.f32.f16 %f16, %rs19;}

	// end inline asm
	ld.shared.u16 	%rs20, [%r9+8];
	// begin inline asm
	{  cvt.f32.f16 %f17, %rs20;}

	// end inline asm
	fma.rn.f32 	%f44, %f16, %f17, %f43;
	ld.shared.u16 	%rs21, [%r8+10];
	// begin inline asm
	{  cvt.f32.f16 %f18, %rs21;}

	// end inline asm
	ld.shared.u16 	%rs22, [%r9+10];
	// begin inline asm
	{  cvt.f32.f16 %f19, %rs22;}

	// end inline asm
	fma.rn.f32 	%f45, %f18, %f19, %f44;
	ld.shared.u16 	%rs23, [%r8+12];
	// begin inline asm
	{  cvt.f32.f16 %f20, %rs23;}

	// end inline asm
	ld.shared.u16 	%rs24, [%r9+12];
	// begin inline asm
	{  cvt.f32.f16 %f21, %rs24;}

	// end inline asm
	fma.rn.f32 	%f46, %f20, %f21, %f45;
	ld.shared.u16 	%rs25, [%r8+14];
	// begin inline asm
	{  cvt.f32.f16 %f22, %rs25;}

	// end inline asm
	ld.shared.u16 	%rs26, [%r9+14];
	// begin inline asm
	{  cvt.f32.f16 %f23, %rs26;}

	// end inline asm
	fma.rn.f32 	%f47, %f22, %f23, %f46;
	ld.shared.u16 	%rs27, [%r8+16];
	// begin inline asm
	{  cvt.f32.f16 %f24, %rs27;}

	// end inline asm
	ld.shared.u16 	%rs28, [%r9+16];
	// begin inline asm
	{  cvt.f32.f16 %f25, %rs28;}

	// end inline asm
	fma.rn.f32 	%f48, %f24, %f25, %f47;
	ld.shared.u16 	%rs29, [%r8+18];
	// begin inline asm
	{  cvt.f32.f16 %f26, %rs29;}

	// end inline asm
	ld.shared.u16 	%rs30, [%r9+18];
	// begin inline asm
	{  cvt.f32.f16 %f27, %rs30;}

	// end inline asm
	fma.rn.f32 	%f49, %f26, %f27, %f48;
	ld.shared.u16 	%rs31, [%r8+20];
	// begin inline asm
	{  cvt.f32.f16 %f28, %rs31;}

	// end inline asm
	ld.shared.u16 	%rs32, [%r9+20];
	// begin inline asm
	{  cvt.f32.f16 %f29, %rs32;}

	// end inline asm
	fma.rn.f32 	%f50, %f28, %f29, %f49;
	ld.shared.u16 	%rs33, [%r8+22];
	// begin inline asm
	{  cvt.f32.f16 %f30, %rs33;}

	// end inline asm
	ld.shared.u16 	%rs34, [%r9+22];
	// begin inline asm
	{  cvt.f32.f16 %f31, %rs34;}

	// end inline asm
	fma.rn.f32 	%f51, %f30, %f31, %f50;
	ld.shared.u16 	%rs35, [%r8+24];
	// begin inline asm
	{  cvt.f32.f16 %f32, %rs35;}

	// end inline asm
	ld.shared.u16 	%rs36, [%r9+24];
	// begin inline asm
	{  cvt.f32.f16 %f33, %rs36;}

	// end inline asm
	fma.rn.f32 	%f52, %f32, %f33, %f51;
	ld.shared.u16 	%rs37, [%r8+26];
	// begin inline asm
	{  cvt.f32.f16 %f34, %rs37;}

	// end inline asm
	ld.shared.u16 	%rs38, [%r9+26];
	// begin inline asm
	{  cvt.f32.f16 %f35, %rs38;}

	// end inline asm
	fma.rn.f32 	%f53, %f34, %f35, %f52;
	ld.shared.u16 	%rs39, [%r8+28];
	// begin inline asm
	{  cvt.f32.f16 %f36, %rs39;}

	// end inline asm
	ld.shared.u16 	%rs40, [%r9+28];
	// begin inline asm
	{  cvt.f32.f16 %f37, %rs40;}

	// end inline asm
	fma.rn.f32 	%f54, %f36, %f37, %f53;
	ld.shared.u16 	%rs41, [%r8+30];
	// begin inline asm
	{  cvt.f32.f16 %f38, %rs41;}

	// end inline asm
	ld.shared.u16 	%rs42, [%r9+30];
	// begin inline asm
	{  cvt.f32.f16 %f39, %rs42;}

	// end inline asm
	fma.rn.f32 	%f57, %f38, %f39, %f54;
	bar.sync 	0;
	add.s32 	%r34, %r34, %r11;
	add.s64 	%rd15, %rd15, 32;
	add.s32 	%r33, %r33, 16;
	add.s32 	%r35, %r35, 16;
	setp.lt.s32 	%p8, %r35, %r20;
	@%p8 bra 	$L__BB0_2;

$L__BB0_9:
	setp.ge.s32 	%p9, %r5, %r19;
	setp.ge.s32 	%p10, %r2, %r18;
	or.pred  	%p11, %p10, %p9;
	@%p11 bra 	$L__BB0_11;

	cvta.to.global.u64 	%rd12, %rd7;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs43, %f57;}

	// end inline asm
	// begin inline asm
	{mul.f16 %rs44,%rs43,%rs8;
}
	// end inline asm
	mad.lo.s32 	%r32, %r2, %r19, %r5;
	mul.wide.s32 	%rd13, %r32, 2;
	add.s64 	%rd14, %rd12, %rd13;
	ld.global.u16 	%rs48, [%rd14];
	// begin inline asm
	{mul.f16 %rs47,%rs48,%rs7;
}
	// end inline asm
	// begin inline asm
	{add.f16 %rs50,%rs44,%rs47;
}
	// end inline asm
	st.global.u16 	[%rd14], %rs50;

$L__BB0_11:
	ret;

}

