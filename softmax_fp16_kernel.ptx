//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-30672275
// Cuda compilation tools, release 11.5, V11.5.119
// Based on NVVM 7.0.1
//

.version 7.5
.target sm_86
.address_size 64

	// .globl	softmax_fp16
// _ZZ12softmax_fp16E5s_sum has been demoted
.extern .shared .align 16 .b8 shared_max[];

.visible .entry softmax_fp16(
	.param .u64 softmax_fp16_param_0,
	.param .u64 softmax_fp16_param_1,
	.param .u32 softmax_fp16_param_2,
	.param .u32 softmax_fp16_param_3
)
{
	.reg .pred 	%p<11>;
	.reg .b16 	%rs<11>;
	.reg .f32 	%f<41>;
	.reg .b32 	%r<30>;
	.reg .b64 	%rd<12>;
	// demoted variable
	.shared .align 4 .f32 _ZZ12softmax_fp16E5s_sum;

	ld.param.u64 	%rd3, [softmax_fp16_param_0];
	ld.param.u64 	%rd4, [softmax_fp16_param_1];
	ld.param.u32 	%r14, [softmax_fp16_param_3];
	cvta.to.global.u64 	%rd1, %rd4;
	cvta.to.global.u64 	%rd2, %rd3;
	mov.u32 	%r15, %ctaid.x;
	mul.lo.s32 	%r1, %r15, %r14;
	mov.u32 	%r29, %tid.x;
	setp.ge.s32 	%p1, %r29, %r14;
	mov.f32 	%f38, 0fFF800000;
	mov.u32 	%r3, %ntid.x;
	@%p1 bra 	$L__BB0_3;

	mov.u32 	%r26, %r29;

$L__BB0_2:
	add.s32 	%r16, %r26, %r1;
	mul.wide.s32 	%rd5, %r16, 2;
	add.s64 	%rd6, %rd1, %rd5;
	ld.global.u16 	%rs1, [%rd6];
	// begin inline asm
	{  cvt.f32.f16 %f11, %rs1;}

	// end inline asm
	max.f32 	%f38, %f38, %f11;
	add.s32 	%r26, %r26, %r3;
	setp.lt.s32 	%p2, %r26, %r14;
	@%p2 bra 	$L__BB0_2;

$L__BB0_3:
	// begin inline asm
	{  cvt.rn.f16.f32 %rs2, %f38;}

	// end inline asm
	shl.b32 	%r17, %r29, 1;
	mov.u32 	%r18, shared_max;
	add.s32 	%r6, %r18, %r17;
	st.shared.u16 	[%r6], %rs2;
	bar.sync 	0;
	shr.u32 	%r27, %r3, 1;
	setp.eq.s32 	%p3, %r27, 0;
	@%p3 bra 	$L__BB0_8;

$L__BB0_5:
	setp.ge.s32 	%p4, %r29, %r27;
	@%p4 bra 	$L__BB0_7;

	ld.shared.u16 	%rs4, [%r6];
	shl.b32 	%r19, %r27, 1;
	add.s32 	%r20, %r6, %r19;
	ld.shared.u16 	%rs5, [%r20];
	// begin inline asm
	{max.f16 %rs3,%rs4,%rs5;
}
	// end inline asm
	st.shared.u16 	[%r6], %rs3;

$L__BB0_7:
	bar.sync 	0;
	shr.s32 	%r9, %r27, 1;
	setp.gt.s32 	%p5, %r27, 1;
	mov.u32 	%r27, %r9;
	@%p5 bra 	$L__BB0_5;

$L__BB0_8:
	ld.shared.u16 	%rs6, [shared_max];
	// begin inline asm
	{  cvt.f32.f16 %f13, %rs6;}

	// end inline asm
	mov.f32 	%f40, 0f00000000;
	@%p1 bra 	$L__BB0_11;

	mov.f32 	%f19, 0f3F000000;
	mov.f32 	%f20, 0f3BBB989D;
	mov.u32 	%r28, %r29;

$L__BB0_10:
	add.s32 	%r21, %r28, %r1;
	mul.wide.s32 	%rd7, %r21, 2;
	add.s64 	%rd8, %rd1, %rd7;
	ld.global.u16 	%rs7, [%rd8];
	// begin inline asm
	{  cvt.f32.f16 %f16, %rs7;}

	// end inline asm
	sub.f32 	%f18, %f16, %f13;
	fma.rn.f32 	%f21, %f18, %f20, %f19;
	mov.f32 	%f22, 0f3FB8AA3B;
	mov.f32 	%f23, 0f437C0000;
	cvt.sat.f32.f32 	%f24, %f21;
	mov.f32 	%f25, 0f4B400001;
	fma.rm.f32 	%f26, %f24, %f23, %f25;
	add.f32 	%f27, %f26, 0fCB40007F;
	neg.f32 	%f28, %f27;
	fma.rn.f32 	%f29, %f18, %f22, %f28;
	mov.f32 	%f30, 0f32A57060;
	fma.rn.f32 	%f31, %f18, %f30, %f29;
	mov.b32 	%r22, %f26;
	shl.b32 	%r23, %r22, 23;
	mov.b32 	%f32, %r23;
	ex2.approx.ftz.f32 	%f33, %f31;
	mul.f32 	%f17, %f33, %f32;
	add.f32 	%f40, %f40, %f17;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs8, %f17;}

	// end inline asm
	add.s64 	%rd9, %rd2, %rd7;
	st.global.u16 	[%rd9], %rs8;
	add.s32 	%r28, %r28, %r3;
	setp.lt.s32 	%p7, %r28, %r14;
	@%p7 bra 	$L__BB0_10;

$L__BB0_11:
	mov.u32 	%r24, _ZZ12softmax_fp16E5s_sum;
	atom.shared.add.f32 	%f34, [%r24], %f40;
	bar.sync 	0;
	setp.ne.s32 	%p8, %r29, 0;
	@%p8 bra 	$L__BB0_13;

	st.shared.f32 	[_ZZ12softmax_fp16E5s_sum], %f40;

$L__BB0_13:
	bar.sync 	0;
	@%p1 bra 	$L__BB0_16;

	ld.shared.f32 	%f8, [_ZZ12softmax_fp16E5s_sum];

$L__BB0_15:
	add.s32 	%r25, %r29, %r1;
	mul.wide.s32 	%rd10, %r25, 2;
	add.s64 	%rd11, %rd2, %rd10;
	ld.global.u16 	%rs9, [%rd11];
	// begin inline asm
	{  cvt.f32.f16 %f35, %rs9;}

	// end inline asm
	div.rn.f32 	%f36, %f35, %f8;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs10, %f36;}

	// end inline asm
	st.global.u16 	[%rd11], %rs10;
	add.s32 	%r29, %r29, %r3;
	setp.lt.s32 	%p10, %r29, %r14;
	@%p10 bra 	$L__BB0_15;

$L__BB0_16:
	ret;

}

